{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "supported-discipline",
   "metadata": {},
   "source": [
    "# Melodic Expectation with Recurrent Neural Networks\n",
    "\n",
    "In this notebook we will explore how to compute musical expectation with Recurrent Neural Networks (RNNs).\n",
    "\n",
    "RNNs are a family of neural networks designed to model sequential data (like music!).\n",
    "\n",
    "## Melodic Expectation\n",
    "\n",
    "We can model musical expectation as a supervised learning problem, by training a model to predict the next event in the sequence. In particular, we can treat this problem as a *supervised classification problem* in which we present the network with a sequence of inputs encoding pitch and temporal information (e.g., note duration, inter-onset interval, ...), and predicting the next event is equivalent to *classifiying* the next event (i.e., which pitch and duration will the next event have).\n",
    "\n",
    "More formally, we can define this problem as\n",
    "\n",
    "$$p(\\mathbf{x}_{t} \\mid \\mathbf{x}_{t - 1}, \\mathbf{x}_{t - 2}, \\dots) = p(\\mathbf{x}_t \\mid \\mathbf{y}_t)$$\n",
    "\n",
    "where \n",
    "\n",
    "* $\\mathbf{x}_t$ is the melodic event (i.e., note and duration) at time step $t$. We will denote $v_{ti}$ the $i$-th possible note at time $t$.\n",
    "* $p(\\mathbf{x}_{t} \\mid \\mathbf{x}_{t - 1}, \\mathbf{x}_{t - 2}, \\dots)$ is the probability of event $\\mathbf{x}_t$ given the sequence $\\mathbf{X}_{1:t-1} = \\{\\mathbf{x}_1, \\dots, \\mathbf{x}_{t-1}\\}$\n",
    "* $p(\\mathbf{x}_t \\mid \\mathbf{y}_t)$ is the probability of $\\mathbf{x}_t$ parametrized by the $\\mathbf{y}_t$, the output of the RNN. We will come back to this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import some stuff\n",
    "import os\n",
    "# Uncomment this line if the kernel keeps crashing\n",
    "# See https://stackoverflow.com/a/53014308\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "import glob\n",
    "import logging\n",
    "\n",
    "from typing import Tuple, List, Union, Optional\n",
    "\n",
    "import numpy as np\n",
    "import partitura as pt\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, ConcatDataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from rnn import find_nearest\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "# Define seed for random number generator\n",
    "RNG = np.random.RandomState(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-munich",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "We can load the data and compute the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn import load_data\n",
    "\n",
    "# To filter out short melodies The minimum number of notes that a sequence should have\n",
    "min_seq_len = 10\n",
    "sequences = load_data(min_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-marijuana",
   "metadata": {},
   "source": [
    "For simplicity, we are going to assume that pitch and duration/temporal information are independent, so that modeling melodic expectation can be simplified as\n",
    "\n",
    "$$p(\\mathbf{x}_t \\mid \\mathbf{y}_t) = p(\\text{pitch}_t \\mid \\mathbf{y}_t) p(\\text{duration}_t \\mid \\mathbf{y}_t)$$\n",
    "\n",
    "(for simplicity, we are using \"duration\" as the feature representing temporal information, but we can use IOI, or other features)\n",
    "\n",
    "Since we have natural \"categories\" for pitch and duration (i.e., each MIDI note number representing the pitch, and each of the individual \"duration\" values), we can use a one-hot-encoding for each of these features.\n",
    "\n",
    "$$\\mathbf{x}_t = \\left(\\begin{array}{c}\\mathbf{pitch}_tÂ \\\\ \\mathbf{duration}_t\\end{array} \\right)$$\n",
    "\n",
    "where $p_{it} = 1$ if pitch $i$ is the \"active\" note at time $t$ and $0$ otherwise (and similar for duration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which features to use\n",
    "# Useful info\n",
    "field_names = [\n",
    "    \"pitch\", \n",
    "    \"onset_sec\", \n",
    "    \"duration_sec\"\n",
    "]\n",
    "\n",
    "def get_features(seq: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract features from note arrays.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    seq : np.ndarray\n",
    "        A note array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x : np.ndarray\n",
    "        Features extracted from a note array.\n",
    "    \"\"\"\n",
    "    # Possible things to try:\n",
    "    # * Use inter onset interval (IOI) instead of duration\n",
    "    # * Code rest (and duration) instead of IOI\n",
    "    feature_names = [\n",
    "        \"pitch\",\n",
    "        \"duration_sec\"\n",
    "    ]\n",
    "    \n",
    "    # construct features\n",
    "    x = np.column_stack([seq[fn] for fn in feature_names])\n",
    "    return x\n",
    "\n",
    "Data = [get_features(x) for x in sequences]\n",
    "\n",
    "# MIDIs were generated at 100bpm\n",
    "dur_encoder = OneHotEncoder().fit(np.hstack([np.round(x[:, 1] * 100 / 60, 3) for x in Data]).reshape(-1, 1))\n",
    "pitch_encoder = OneHotEncoder().fit(np.hstack([x[:, 0] for x in Data]).reshape(-1, 1))\n",
    "\n",
    "def one_hot_encoding(seq: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    A concatenated encoding of pitch and duration as one hot vectors\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    seq : np.ndarray\n",
    "        A note array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A 2D array. Each column corresponds to the encoding of one note\n",
    "        Each note is represented as a one-hot encoding of pitch and a one-hot\n",
    "        encoding of duration\n",
    "    \"\"\"\n",
    "    pitch_encoding = pitch_encoder.transform(seq[\"pitch\"].reshape(-1, 1)).toarray()\n",
    "    duration_encodig = dur_encoder.transform(np.round(seq[\"duration_sec\"].reshape(-1,1) * 100 / 60, 3)).toarray()\n",
    "    return np.column_stack([pitch_encoding, duration_encoding])\n",
    "\n",
    "data_one_hot = []\n",
    "for x in Data:\n",
    "    pitch_features = pitch_encoder.transform(x[:, 0].reshape(-1, 1)).toarray()\n",
    "    duration_features = dur_encoder.transform(np.round(x[:, 1] * 100 / 60 , 3).reshape(-1, 1)).toarray()\n",
    "    data_one_hot.append(np.column_stack([pitch_features, duration_features]))\n",
    "    \n",
    "input_size = data_one_hot[0].shape[1]\n",
    "pitch_idxs = np.arange(len(pitch_encoder.categories_[0]))\n",
    "dur_idxs = np.arange(len(pitch_encoder.categories_[0]), len(pitch_encoder.categories_[0]) + len(dur_encoder.categories_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-underground",
   "metadata": {},
   "source": [
    "This is an alternative implementation using pre-defined duration categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "durations_quantized = np.array([1/8, 1/6, 1/4, 1/3, 1/2, 1, 1.5, 2, 3, 4])\n",
    "\n",
    "def one_hot_encoding(seq: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    A concatenated encoding of pitch and duration as one hot vectors\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    seq : np.ndarray\n",
    "        A note array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        A 2D array. Each column corresponds to the encoding of one note\n",
    "        Each note is represented as a one-hot encoding of pitch and a one-hot\n",
    "        encoding of (quantized) duration\n",
    "    \"\"\"\n",
    "    pitch_encoding = np.zeros((len(seq), 128))\n",
    "    pitch_encoding[(np.arange(len(seq)), seq[\"pitch\"])] = 1\n",
    "    \n",
    "    duration_encoding = np.zeros((len(seq), len(durations_quantized)))\n",
    "    duration_encoding[(np.arange(len(seq)), find_nearest(durations_quantized, seq[\"duration_sec\"] * 10/6))] = 1\n",
    "    \n",
    "    return np.column_stack([pitch_encoding, duration_encoding])\n",
    "\n",
    "input_size = 128 + len(durations_quantized)\n",
    "pitch_idxs = np.arange(128)\n",
    "dur_idxs = np.arange(128, 128 + len(durations_quantized))\n",
    "\n",
    "data_one_hot = [one_hot_encoding(seq) for seq in sequences]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-finding",
   "metadata": {},
   "source": [
    "### Task 1: Prepare Dataset\n",
    "\n",
    "* Decide how to encode temporal information (use durations, ioi, encode rests?). Hint: You can use the same features as in the Markiv Chain Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_one_hot\n",
    "# define one_hot_encoder for the temporal information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-cocktail",
   "metadata": {},
   "source": [
    "Ideally, we would like our data handling code to be decoupled from the model definition and training. PyTorch provides a convenient way to handle data with the `torch.utils.data.Dataset` and `torch.utils.data.DataLoader` classes.\n",
    "\n",
    "* `Dataset` stores the samples and their corresponding targets\n",
    "* `DataLoader` wraps an iterable around the `Dataset` to enable easy access to the samples.\n",
    "\n",
    "We can create a custom `Dataset` for our musical data. A custom `Dataset` class must implement three functions: `__init__`, `__len__`, and `__getitem__`.\n",
    "\n",
    "In our case, we would like a dataset for which the inputs would be sequences of length $S$\n",
    "\n",
    "$$ \\mathbf{X} = \\{\\mathbf{x_i}, \\dots, \\mathbf{x}_{i + S}\\}$$\n",
    "\n",
    "and their corresponding targets are a one-step shifted version of the inputs, i.e.,\n",
    "\n",
    "$$ \\mathbf{Y} = \\{\\mathbf{x}_{i+1}, \\dots, \\mathbf{x}_{i + S + 1}\\}$$\n",
    "\n",
    "We can define such a dataset with the following `PieceDataset` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PieceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for sequential predictions.\n",
    "    In this case, if data is a sequence of datapoints,\n",
    "    the inputs (x) will be x[t:t+seq_len] and outputs would\n",
    "    be (y) x[t+1:t+seq_len+1] (i.e., the next events)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        data: List[np.ndarray], \n",
    "        seq_len: int=min_seq_len\n",
    "    ) -> None:\n",
    "        self.data = data\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    @property\n",
    "    def piecewise(self) -> bool:\n",
    "        return self.seq_len == -1\n",
    "\n",
    "    def __getitem__(self, i: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        if self.piecewise:\n",
    "            return self._get_item_piecewise(i)\n",
    "        else:\n",
    "            return self._get_item_sequencewise(i)\n",
    "\n",
    "    def _get_item_piecewise(self, i: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        if i > 0:\n",
    "            raise IndexError\n",
    "        x = self.data[:-1]\n",
    "        y = self.data[1:]\n",
    "        return x, y\n",
    "\n",
    "    def _get_item_sequencewise(self, i: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        if i + self.seq_len - 1 > len(self.data):\n",
    "            raise IndexError\n",
    "        x = self.data[i:i + self.seq_len]\n",
    "        y = self.data[i + 1: i + self.seq_len + 1]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        if self.piecewise:\n",
    "            return 1\n",
    "        else:\n",
    "            return max(0, len(self.data) - self.seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-ordering",
   "metadata": {},
   "source": [
    "## Defining the Model\n",
    "\n",
    "We can now define an RNN!\n",
    "\n",
    "PyTorch provides a very convenient way to create neural networks with the `torch.nn.Module` class. This class allows us to define a custom neural architecture, and define how the information should flow in the forward pass.\n",
    "\n",
    "A module should implement a  `forward` method to define the forward pass. Additionally, RNNs should implement a method for initializing the hidden recurrent layers.\n",
    "\n",
    "The following code is a simple recurrent model consisting of\n",
    "\n",
    "* 1 recurrent layer (can be defined as a vanilla RNN, an LSTM or GRU)\n",
    "* 1 hidden dense layer to embed the output of the recurrent layer\n",
    "\n",
    "In this case, the dimension of the inputs are the same as the dimensions of the output, since we want to predict the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A Simple Recurrent Model consisting of\n",
    "    an input -> RNN -> dense layer -> output (same size as the input)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : int\n",
    "        Size of the input\n",
    "    recurrent_size : int\n",
    "        Size of the recurrent layer\n",
    "    hidden_size : int\n",
    "        Size of the hidden dense layer\n",
    "    dropout : float\n",
    "        Probability of droput\n",
    "    batch_first : bool\n",
    "        Whether the first dimension in the \n",
    "        input array is the batch.\n",
    "    dtype : type\n",
    "        Data type of the inputs and weights\n",
    "    rnn_layer: nn.RNN\n",
    "        A subclass of nn.RNN defining a recurrent layer.\n",
    "    device : torch.device\n",
    "        Whether to run in a GPU or a CPU\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        recurrent_size: int, \n",
    "        hidden_size: int,\n",
    "        dropout: float = 0.0,\n",
    "        batch_first: bool =True,\n",
    "        dtype: type = torch.float32,\n",
    "        rnn_layer: nn.RNN = nn.LSTM,\n",
    "        device: Optional[torch.device] = None\n",
    "    ) -> None:\n",
    "        nn.Module.__init__(self)\n",
    "        self.input_size = input_size\n",
    "        self.recurrent_size = recurrent_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = input_size\n",
    "        self.n_layers = 1\n",
    "        self.batch_first = batch_first\n",
    "        self.device = device if device is not None else torch.device('cpu')\n",
    "        self.to(self.device)\n",
    "        self.dtype = dtype\n",
    "        self.rnn = rnn_layer(input_size, \n",
    "                             self.recurrent_size,\n",
    "                             self.n_layers,\n",
    "                             batch_first=batch_first, \n",
    "                             dropout=dropout,\n",
    "                             bidirectional=False)\n",
    "        dense_in_features = self.recurrent_size\n",
    "        self.dense = nn.Linear(in_features=dense_in_features,\n",
    "                               out_features=self.hidden_size)\n",
    "        self.output = nn.Linear(in_features=self.hidden_size,\n",
    "                                out_features=self.output_size)\n",
    "\n",
    "    def init_hidden(self, batch_size: int) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Initialize hidden recurrent layer.\n",
    "        \"\"\"\n",
    "        if isinstance(self.rnn, nn.LSTM):\n",
    "            h0 = torch.zeros(self.n_layers, batch_size, self.recurrent_size).to(self.dtype)\n",
    "            c0 = torch.zeros(self.n_layers, batch_size, self.recurrent_size).to(self.dtype)\n",
    "            return (h0, c0)\n",
    "        else:\n",
    "            return torch.zeros(self.n_layers, batch_size, self.recurrent_size).to(self.dtype)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        h0 = self.init_hidden(batch_size)\n",
    "        output, h = self.rnn(x, h0)\n",
    "        flatten_shape = self.recurrent_size\n",
    "        dense = self.dense(output.contiguous().view(-1, flatten_shape))\n",
    "        y = self.output(dense)\n",
    "        y = y.view(batch_size, seq_len, self.output_size)\n",
    "\n",
    "        return y\n",
    "    \n",
    "rnn = RecurrentModel(input_size=input_size, recurrent_size=64, hidden_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-result",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "In order to train the model, we need to specify a loss function.\n",
    "\n",
    "A common loss function for classification tasks is the Cross Entropy Loss. Since our network is basically predicting (classifiying) a pitch and a duration with different parts of the output vector, we can simply compute the cross entropy of the pitch and the cross entropy of the duration, and add the together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchDurationCrossEntropyLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Cross Entropy of Pitch and Duration\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        pitch_idxs: np.ndarray, \n",
    "        dur_idxs: np.ndarray, \n",
    "        weights: List[float] = [0.5, 0.5], \n",
    "        name: str = 'PitchDurationCrossEntropyLoss',\n",
    "    ) -> None:\n",
    "        nn.Module.__init__(self)\n",
    "        self.pitch_idxs = pitch_idxs\n",
    "        self.dur_idxs = dur_idxs    \n",
    "        self.weights = weights\n",
    "        self.name = name\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def __call__(\n",
    "        self, \n",
    "        predictions: torch.Tensor, \n",
    "        targets: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        pitch_preds = predictions[:, :, self.pitch_idxs]\n",
    "        pitch_preds = pitch_preds.view(-1, pitch_preds.size(2))\n",
    "        dur_preds = predictions[:, :, self.dur_idxs]\n",
    "        dur_preds = dur_preds.view(-1, dur_preds.size(2))\n",
    "        pitch_target = targets[:, :, self.pitch_idxs].argmax(-1).view(-1).to(torch.long)\n",
    "        dur_target = targets[:, :, self.dur_idxs].argmax(-1).view(-1).to(torch.long)\n",
    "        loss = (self.weights[0] * self.ce(pitch_preds, pitch_target) + \n",
    "                self.weights[1] * self.ce(dur_preds, dur_target))\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-sailing",
   "metadata": {},
   "source": [
    "We now split the data into training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset will be the concatenation of the datasets for each piece\n",
    "dataset = ConcatDataset([PieceDataset(piece, seq_len=-1) for piece in data_one_hot])\n",
    "\n",
    "# Select training, test and validation sets\n",
    "dataset_idx = np.arange(len(dataset))\n",
    "\n",
    "valid_size = 0.2\n",
    "test_size = 0.3\n",
    "batch_size = 1\n",
    "\n",
    "trainvalid_idx, test_idx = train_test_split(dataset_idx, \n",
    "                                            test_size=0.33,\n",
    "                                            random_state=RNG)\n",
    "\n",
    "RNG.shuffle(trainvalid_idx)\n",
    "len_valid = int(np.round(len(dataset) * valid_size))\n",
    "valid_idx = dataset_idx[0:len_valid]\n",
    "train_idx = dataset_idx[len_valid:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "valid_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-realtor",
   "metadata": {},
   "source": [
    "We can now setup the training of the model!\n",
    "\n",
    "The `SupervisedTrainer` class is a helper to setup a function to train a model in a supervised way.\n",
    "\n",
    "**Try changing a couple settings**\n",
    "\n",
    "* Adjusting learning rate\n",
    "* Selecting an Optimizer (see [torch.optim](https://pytorch.org/docs/stable/optim.html?highlight=optimization))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn import SupervisedTrainer\n",
    "\n",
    "train_loss = PitchDurationCrossEntropyLoss(pitch_idxs, dur_idxs, name=\"Train\")\n",
    "valid_loss = PitchDurationCrossEntropyLoss(pitch_idxs, dur_idxs, name=\"Validation\")\n",
    "learning_rate = 0.01\n",
    "epochs = 15\n",
    "early_stopping = 3\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "trainer = SupervisedTrainer(model=rnn,\n",
    "                            train_loss=train_loss,\n",
    "                            valid_loss=valid_loss,\n",
    "                            train_dataloader=train_loader,\n",
    "                            valid_dataloader=valid_loader,\n",
    "                            epochs=epochs,\n",
    "                            save_freq=1, # This parameter controlls how often the model is validated\n",
    "                            early_stopping=early_stopping,\n",
    "                            optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-customs",
   "metadata": {},
   "source": [
    "Now we are ready to train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-crime",
   "metadata": {},
   "source": [
    "It is useful to have a look at the training curves. Since ANNs are prone to overfitting, comparing the behavior of the training loss and the validation loss can be very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-declaration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loss_fn = os.path.join(\".\", \"train_loss.txt\")\n",
    "train_loss_curve = np.loadtxt(train_loss_fn)\n",
    "valid_loss_fn = os.path.join(\".\", \"valid_loss.txt\")\n",
    "valid_loss_curve = np.loadtxt(valid_loss_fn)\n",
    "plt.plot(train_loss_curve[:, 0], train_loss_curve[:, 1], label=\"Training loss\")\n",
    "plt.plot(valid_loss_curve[:, 0], valid_loss_curve[:, 1], label=\"Validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Cross Entropy\")\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(\n",
    "    model: nn.Module, \n",
    "    test_loader: DataLoader, \n",
    "    loss: nn.Module=valid_loss\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Evaluate the model\n",
    "    \"\"\"\n",
    "    test_ce = []\n",
    "    model.eval()\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "        preds = model(x.to(model.dtype))\n",
    "        ce = loss(preds, y)\n",
    "        test_ce.append(ce.item())\n",
    "        \n",
    "    return np.mean(test_ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-terrace",
   "metadata": {},
   "source": [
    "**Task 2**\n",
    "\n",
    "Define and train 2 different models. You can decide on the architecture and the optimization.\n",
    "\n",
    "Compare the performance of both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross entropy of the trained model on the test set\n",
    "eval_model(rnn, test_loader, loss=valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-indian",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Compute the probability of an event musical sequences. How would you compute how probable is an event?\n",
    "\n",
    "You can select one of the sequences in the test set, or define your own melody and see how probable is the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn import prob_x_given_context\n",
    "\n",
    "probe_tone_probs = np.zeros(12)\n",
    "for pt in range(12):\n",
    "    c_maj_ascending = np.array([(60, 0.5),\n",
    "                                (62, 0.5),\n",
    "                                (64, 0.5),\n",
    "                                (65, 0.5),\n",
    "                                (67, 0.5),\n",
    "                                (69, 0.5),\n",
    "                                (71, 0.5),\n",
    "                                (72 + pt, 0.5)],\n",
    "                              dtype=[(\"pitch\", \"i4\"),\n",
    "                                    (\"duration_sec\", \"f4\")])\n",
    "\n",
    "    c_maj_ascending_features = one_hot_encoding(c_maj_ascending)\n",
    "\n",
    "    ppt = prob_x_given_context(rnn=rnn,\n",
    "                               x=c_maj_ascending_features[-1], \n",
    "                               context=c_maj_ascending_features[:-1],\n",
    "                               pitch_idxs=pitch_idxs,\n",
    "                               dur_idxs=dur_idxs)\n",
    "    probe_tone_probs[pt] = ppt\n",
    "    \n",
    "plt.plot(probe_tone_probs)\n",
    "plt.xticks(np.arange(12), [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"])\n",
    "plt.xlabel(\"Probe Tone\")\n",
    "plt.ylabel(\"Probe tone probability\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
